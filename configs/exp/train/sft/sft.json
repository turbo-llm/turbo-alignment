{
  "train_dataset_settings": {
    "sources": [
      {
        "name": "train_chat",
        "records_path": "/from_s3/dataset/train_chat.jsonl",
        "sample_rate": 0.01
      }
    ],
    "prompt_template": "configs/exp/templates/gemma2.jinja",
    "dataset_type": "chat",
    "max_tokens_count": 2000
  },
  "val_dataset_settings": {
    "sources": [
      {
        "name": "val_chat",
        "records_path": "/from_s3/dataset/val_chat.jsonl",
        "sample_rate": 0.01
      }
    ],
    "prompt_template": "/app/configs/exp/templates/gemma2.jinja",
    "dataset_type": "chat",
    "max_tokens_count": 2000
  },
  "model_settings": {
    "model_path": "/from_s3/model",
    "model_type": "causal",
    "transformers_settings": {},
    "model_kwargs": {
      "attn_implementation": "eager"
    }
  },
  "cherry_pick_settings": {
    "generator_transformers_settings": {
      "num_beams": 3,
      "max_new_tokens": 512,
      "repetition_penalty": 1.02,
      "stop_strings": "<|eot_id|>"
    },
    "custom_generation_settings": {
      "skip_special_tokens": false
    },
    "dataset_settings": {
      "sources": [
        {
          "name": "cherrypick_chat",
          "records_path": "/from_s3/dataset/val_chat150.jsonl",
          "num_samples": 150
        }
      ],
      "prompt_template": "configs/exp/templates/gemma2.jinja",
      "dataset_type": "chat",
      "max_tokens_count": 2000,
      "random_cut": true
    },
    "metric_settings": [
      {
        "type": "length", 
        "parameters": {
          "need_average": [true]
        }
      }
    ]
  },
  "tokenizer_settings": {"use_fast":  true},
  "trainer_settings": {
    "evaluation_strategy": "steps",
    "save_total_limit": 5,
    "load_best_model_at_end": false,
    "per_device_train_batch_size": 1,
    "per_device_eval_batch_size": 1,
    "gradient_accumulation_steps": 16,
    "logging_steps": 1,
    "eval_steps": 64,
    "save_steps": 64,
    "learning_rate": 1e-6,
    "num_train_epochs": 2,
    "lr_scheduler_type": "linear",
    "warmup_ratio": 0.03,
    "fp16": false,
    "bf16": true,
    "deepspeed": "configs/exp/deepspeed/stage2.json",
    "optim": "adamw_torch",
    "adam_beta1": 0.9,
    "adam_beta2": 0.98,
    "adam_epsilon": 1e-6,
    "weight_decay": 0.01,
    "max_grad_norm": 0.11
  },
  "wandb_settings": {
    "project_name": "alignment",
    "run_name": "sft",
    "entity": "turbo-alignment"
  },
  "seed": 21,
  "log_path": "train_output"
}
