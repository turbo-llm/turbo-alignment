{
  "train_dataset_settings": {
    "sources": [
      {
        "name": "test",
        "records_path": "tests/fixtures/datasets/chat/train_chat_rag.jsonl",
        "sample_rate": 1.0
      }
    ],
    "prompt_template": {
      "role_tag_mapping": {
        "bot": "<bot>",
        "user": "<user>",
        "system": "<system>"
      },
      "prefix_template": "<RS>{role}",
      "suffix_template": "</RS>"
    },
    "dataset_type": "chat",
    "max_tokens_count": 200,
    "only_answer_loss": true
  },
  "val_dataset_settings": {
    "sources": [
      {
        "name": "test",
        "records_path": "tests/fixtures/datasets/chat/train_chat_rag.jsonl",
        "sample_rate": 1.0
      }
    ],
    "prompt_template": {
      "role_tag_mapping": {
        "bot": "<bot>",
        "user": "<user>",
        "system": "<system>"
      },
      "prefix_template": "</RS>{role}",
      "suffix_template": "<RS>"
    },
    "dataset_type": "chat",
    "max_tokens_count": 200,
    "only_answer_loss": true
  },
  "model_settings": {
    "generator_settings": {
      "model_path": "tests/fixtures/models/llama2_tiny",
      "model_type": "causal",
      "transformers_settings": {},
      "embeddings_initialization_strategy": {
        "<RS>": "<s>",
        "</RS>": "</s>",
        "<bot>": "bot",
        "<user>": "user",
        "<system>": "system"
      },
      "peft_settings": {
        "r": 16,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"],
        "task_type": "CAUSAL_LM",
        "modules_to_save": [
          "embed_tokens",
          "lm_head"
        ],
        "name": "LORA"
      }
    },
    "question_encoder_settings": {
      "model_path": "tests/fixtures/models/tiny-bert-embedder",
      "model_type": "encoder",
      "transformers_settings": {},
      "embeddings_initialization_strategy": {}
    },
    "index_settings": {
      "index_path": "tests/fixtures/datasets/rag/fake_wiki.faiss",
      "passages_path": "tests/fixtures/datasets/rag/fake_wiki"
    },
    "retrieval_settings": {
      "n_docs": 1,
      "max_doc_length": 100,
      "query_encoder_max_length": 512
    }
  },
  "cherry_pick_settings": {
    "generator_transformers_settings": {
      "num_beams": 3,
      "max_new_tokens": 16,
      "repetition_penalty": 1.1,
      "stop_strings": "</RS>",
      "do_sample": true
    },
    "custom_generation_settings": {
      "skip_special_tokens": false
    },
    "dataset_settings": {
      "sources": [
        {
          "name": "support",
          "records_path": "tests/fixtures/datasets/chat/train_chat_rag.jsonl",
          "num_samples": 1
        }
      ],
      "prompt_template": {
        "role_tag_mapping": {
          "bot": "<bot>",
          "user": "<user>",
          "system": "<system>"
        },
        "prefix_template": "<RS>{role}",
        "suffix_template": "</RS>"
      },
      "dataset_type": "chat",
      "max_tokens_count": 200,
      "random_cut": true,
      "only_answer_loss": false
    },
    "metric_settings": []
  },
  "tokenizer_settings": {},
  "special_tokens_settings": {
    "bos_token": "<s>",
    "eos_token": "</s>",
    "pad_token": "<pad>"
},
  "trainer_settings": {
    "evaluation_strategy": "epoch",
    "save_strategy": "epoch",
    "per_device_train_batch_size": 1,
    "per_device_eval_batch_size": 1,
    "gradient_accumulation_steps": 1,
    "logging_steps": 1,
    "learning_rate": 0.0004,
    "num_train_epochs": 2,
    "lr_scheduler_type": "linear",
    "warmup_steps": 2,
    "fp16": false,
    "bf16": false,
    "optim": "adamw_torch",
    "adam_beta1": 0.9,
    "adam_beta2": 0.98,
    "adam_epsilon": 1e-6,
    "weight_decay": 0.01,
    "max_grad_norm": 0.11,
    "no_cuda": true,
    "save_total_limit": 1
  },
  "logging_settings": {
    "project_name": "alignment",
    "run_name": "rag",
    "entity": "turbo-alignment"
  },
  "log_path": "test_rag_train_output"
}