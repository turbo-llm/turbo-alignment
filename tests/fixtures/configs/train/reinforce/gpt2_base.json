{
  "train_dataset_settings": {
    "sources": [
      {
        "name": "train_chat",
        "records_path": "tests/fixtures/datasets/chat/train_chat.jsonl",
        "sample_rate": 1.0
      }
    ],
    "prompt_template": {
      "role_tag_mapping": {
        "bot": "assistant",
        "user": "user",
        "system": "system"
      },
      "prefix_template": "<|start_header_id|>{role}<|end_header_id|>\n\n",
      "suffix_template": "<|eot_id|>"
    },
    "dataset_type": "chat",
    "max_tokens_count": 2000,
    "only_answer_loss": true
  },
  "val_dataset_settings": {
    "sources": [
      {
        "name": "val_chat",
        "records_path": "tests/fixtures/datasets/chat/train_chat.jsonl",
        "sample_rate": 1.0
      }
    ],
    "prompt_template": {
      "role_tag_mapping": {
        "bot": "assistant",
        "user": "user",
        "system": "system"
      },
      "prefix_template": "<|start_header_id|>{role}<|end_header_id|>\n\n",
      "suffix_template": "<|eot_id|>"
    },
    "dataset_type": "chat",
    "max_tokens_count": 2000,
    "only_answer_loss": true
  },
  "cherry_pick_settings": {
    "generator_transformers_settings": {
      "num_beams": 1,
      "do_sample": false,
      "stop_strings": "</RS>",
      "max_new_tokens": 8
    },
    "custom_generation_settings": {
      "skip_special_tokens": false
    },
    "dataset_settings": {
      "sources": [
        {
          "name": "chat_test",
          "records_path": "tests/fixtures/datasets/chat/train_chat.jsonl",
          "num_samples": 2
        }
      ],
      "prompt_template": {
        "role_tag_mapping": {
          "bot": "assistant",
          "user": "user",
          "system": "system"
        },
        "prefix_template": "<|start_header_id|>{role}<|end_header_id|>\n\n",
        "suffix_template": "<|eot_id|>"
      },
      "dataset_type": "chat",
      "max_tokens_count": 150,
      "only_answer_loss": true
    },
    "metric_settings": [
      {
        "type": "length",
        "parameters": {
          "need_average": [
            true
          ]
        }
      },
      {
        "type": "kl",
        "parameters": {
          "need_average": [
            true
          ],
          "ref_logits_type": "sft"
        }
      },
      {
        "type": "kl",
        "parameters": {
          "need_average": [
            true
          ],
          "ref_logits_type": "reference"
        }
      }
    ]
  },
  "reward_model_settings": {
    "model_path": "gpt2",
    "model_type": "seq_cls",
    "model_kwargs": {
      "num_labels": 1
    },
    "transformers_settings": {}
  },
  "model_settings": {
    "model_path": "gpt2",
    "model_type": "causal",
    "transformers_settings": {},
    "embeddings_initialization_strategy": {
      "<|start_header_id|>": "<|endoftext|>",
      "<|end_header_id|>": "<|endoftext|>",
      "<|eot_id|>": "<|endoftext|>"
    }
  },
  "tokenizer_settings": {
    "tokenizer_kwargs": {
      "padding_side": "left"
    }
  },
  "trainer_settings": {
    "evaluation_strategy": "steps",
    "per_device_train_batch_size": 1,
    "per_device_eval_batch_size": 1,
    "gradient_accumulation_steps": 1,
    "adam_beta1": 0.9,
    "adam_beta2": 0.95,
    "adam_epsilon": 0.00001,
    "eval_steps": 50,
    "save_steps": 100,
    "save_strategy": "steps",
    "load_best_model_at_end": false,
    "logging_steps": 1,
    "learning_rate": 0.00001,
    "max_steps": 1001,
    "lr_scheduler_type": "constant_with_warmup",
    "warmup_ratio": 0.03,
    "fp16": false,
    "bf16": false,
    "optim": "adamw_torch",
    "weight_decay": 0.0,
    "max_grad_norm": 2,
    "save_total_limit": 11,
    "dataloader_num_workers": 12,
    "stop_token": "<|eot_id|>",
    "temperature": 0.7,
    "non_eos_penalty": true,
    "penalty_reward_value": -1,
    "clip_rewards_min": -1e+8,
    "clip_rewards_max": 1e+8,
    "kl_coef": 0.05,
    "mean_baseline_coef": 0.95,
    "num_samples_for_reward_stats": 10,
    "no_cuda": true
  },
  "special_tokens_settings": {
    "bos_token": "<|endoftext|>",
    "eos_token": "<|endoftext|>",
    "pad_token": "<|endoftext|>"
  },
  "logging_settings": {
    "project_name": "alignment",
    "run_name": "sft",
    "entity": "turbo-alignment"
  },
  "seed": 0,
  "log_path": "train_output"
}
